{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Magic: the Gathering Cards Using TF-IDF\n",
    "This program finds Magic: the Gathering cards that contain similar text to a given card, using sci-kit learn's TF-IDF module.  \n",
    "  \n",
    "TF-IDF stands for \"Term frequency * inverse document frequency.\" It is an algorithm for classifying texts based on weighted word counts, where relatively rare words are weighted more heavily than common ones when they appear in a document. Words that appear often in a card's text but rarely in other cards are treated as the most descriptive keywords for that card, while common words are safely ignored. In this way, we can describe a card's text as a vector representing occurrences of each word and their importance to the text, which can then be easily compared to other vectors to find similar cards.  \n",
    "  \n",
    "You can learn more about TF-IDF here: https://en.wikipedia.org/wiki/Tf%E2%80%93idf and here: https://monkeylearn.com/blog/what-is-tf-idf/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Uses scikit-learn for TF-IDF, and NLTK for pre-processing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Card Texts from MTGJSON\n",
    "You can find complete information on every magic card thanks to the open source project MTGSJSON. We use the 'AtomicCards' json file found here: https://mtgjson.com/downloads/all-files/#atomiccards. I made a smaller version of this file with only the necessary data, called AtomicCards_Small.json, since the full file surpasses GitHub's file size limit. But it should work with the full AtomicCards.json file just as well.  \n",
    "  \n",
    "We could analyze the other properties of a card, but for now we only care about the text similarity.  \n",
    "  \n",
    "The code below shows how to access the raw text of a card:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"\\\"Ach! Hans, Run!\\\"\": [\n",
      "            {\n",
      "                \"legalities\": {},\n",
      "                \"printings\": [\n",
      "                    \"UNH\"\n",
      "                ],\n",
      "                \"text\": \"At the beginning of your upkeep, you may say \\\"Ach! Hans, run! It's the . . .\\\" and the name of a creature card. If you do, search your library for a card with that name, put it onto the battlefield, then shuffle your library. That creature gains haste. Exile it at the beginning of the next end step.\",\n",
      "                \"types\": [\n",
      "                    \"Enchantment\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"\\\"Rumors of My Death . . .\\\"\": [\n",
      "            {\n",
      "                \"legalities\": {},\n",
      "                \"printings\": [\n",
      "                    \"UST\"\n",
      "                ],\n",
      "                \"text\": \"{3}{B}, Exile a permanent you control with a League of Dastardly Doom watermark: Return a permanent card with a League of Dastardly Doom watermark from your graveyard to the battlefield.\",\n",
      "                \"types\": [\n",
      "                    \"Enchantment\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"1996 World Champion\": [\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the mtgJSON file \n",
    "with open('AtomicCards_Small.json', encoding=\"utf8\") as atomicFile:\n",
    "    cards_dict = json.load(atomicFile)\n",
    "\n",
    "# Print some of the json file\n",
    "jsonString = json.dumps(newJsonObject, indent=4, sort_keys=True)\n",
    "print(jsonString[:1123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARD NAME: FIRE // ICE:\n",
      "\n",
      "FACE 1 TEXT: \n",
      "Fire deals 2 damage divided as you choose among one or two targets.\n",
      "\n",
      "FACE 2 TEXT: \n",
      "Tap target permanent.\n",
      "Draw a card.\n"
     ]
    }
   ],
   "source": [
    "# Print the text for \"Fire // Ice\" (both sides)\n",
    "print(\"CARD NAME: FIRE // ICE:\\n\")\n",
    "print(\"FACE 1 TEXT: \")\n",
    "print( cards_dict['data']['Fire // Ice'][0]['text'] + \"\\n\")\n",
    "print(\"FACE 2 TEXT: \")\n",
    "print( cards_dict['data']['Fire // Ice'][1]['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the raw text of a given card.\n",
    "def getRawText(cardName_str):\n",
    "    # Get text from all faces of the card and concatenate it all together.\n",
    "    cardEntry = cards_dict['data'][cardName_str]\n",
    "    return \" \".join([ face['text'] for face in cardEntry if 'text' in face.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Card Text\n",
    "Text is always messy, so we need to clean it up.  \n",
    "  \n",
    "We remove most punctuation, except for meaningful ones: in Magic cards, '{}'s denote a symbol (tap, mana, etc.), '/'s are meaningful for power/toughness, and +/- are also meaningful. We also remove the card's own name from the text; for example, \"Lightning Bolt\" and \"Lightning Mauler\" both contain the rare word \"Lightning\" in their text, so they would be treated as similar even though they are very different cards. We don't want this. Finally, we make all words lowercase for consistency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED TEXT FOR FIRE // ICE: \n",
      " deals 2 damage divided as you choose among one or two targets tap target permanent\n",
      "draw a card\n"
     ]
    }
   ],
   "source": [
    "# Punctuation removal: https://www.semicolonworld.com/question/62188/how-to-strip-string-from-punctuation-except-apostrophes-for-nlp\n",
    "punct = \"!\\\"#$%&'()*,.:;<=>?@[\\]^_`|~\"\n",
    "translator = str.maketrans('', '', punct)\n",
    "\n",
    "def preprocessText(input_text, cardName):\n",
    "    # Delete card's name from card text (or both names if it's a split card)\n",
    "    namelessText = input_text\n",
    "    names = cardName.split(\" // \")\n",
    "    for name in names:\n",
    "        namelessText = namelessText.replace(name, '')\n",
    "    # Make text lowercase\n",
    "    lowerText = namelessText.lower()\n",
    "    # Remove punctuation, keeping {}s. In magic cards, {}s denote a symbol (tap, mana, etc.)\n",
    "    noPunctText = lowerText.translate(translator)\n",
    "    return noPunctText\n",
    "\n",
    "\n",
    "# Example:\n",
    "print(\"CLEANED TEXT FOR FIRE // ICE: \")\n",
    "rawText = getRawText('Fire // Ice')\n",
    "print(preprocessText(rawText, 'Fire // Ice'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to exclude certain cards from our search. Magic has some weird card sets that we should disregard, like the \"Un-\" sets and 'Plane' cards from the Planechase sets. You could also just filter by format legality if desired ('commander', 'duel', 'legacy', 'modern', 'pauper', 'vintage')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude the card 'Chaos Confetti' from the 'Unglued' set?\n",
      "True\n",
      "Exclude the card 'Lightning Bolt'?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def isExcluded(cardName_str):\n",
    "    cardEntry = cards_dict['data'][cardName_str][0]\n",
    "    # Filter out 'Plane' and 'Scheme' cards\n",
    "    if 'Plane' in cardEntry['types'] or 'Scheme' in cardEntry['types']: return True\n",
    "    # Filter out weird sets\n",
    "    excludedSets = {\"PVAN\", \"PCEL\", \"CMB1\", \"UNH\", \"UST\", \"UND\", \"UGL\"}\n",
    "    if not set(cardEntry['printings']).isdisjoint(excludedSets): return True\n",
    "    # Alternatively, filter by format\n",
    "    #if not cardEntry['legalities']['modern'] == 'Legal': return True\n",
    "    return False\n",
    "\n",
    "# Example:\n",
    "print(\"Exclude the card 'Chaos Confetti' from the 'Unglued' set?\")\n",
    "print(isExcluded('Chaos Confetti'))\n",
    "print(\"Exclude the card 'Lightning Bolt'?\")\n",
    "print(isExcluded('Lightning Bolt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Corpus\n",
    "Now we construct our corpus: two parallel lists, where one holds the title of the document (card name) and the other holds the corresponding document (card text). *Note: A dictionary structure might be more organized, but harder to sort.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARD: Abandon Hope\n",
      "TEXT: as an additional cost to cast this spell discard x cards\n",
      "look at target opponents hand and choose x cards from it that player discards those cards\n",
      "\n",
      "CARD: Abandon Reason\n",
      "TEXT: up to two target creatures each get +1/+0 and gain first strike until end of turn\n",
      "madness {1}{r} if you discard this card discard it into exile when you do cast it for its madness cost or put it into your graveyard\n",
      "\n",
      "CARD: Abandoned Outpost\n",
      "TEXT:  enters the battlefield tapped\n",
      "{t} add {w}\n",
      "{t} sacrifice  add one mana of any color\n",
      "\n",
      "etc...\n"
     ]
    }
   ],
   "source": [
    "def constructCorpus():\n",
    "    # Parallel lists\n",
    "    cardNames = []  # aka \"titles\" of our documents (list of strings)\n",
    "    cardTexts = []  # aka our \"documents\" (list of strings)\n",
    "\n",
    "    # For each card, clean up the text, then put its name & text into parallel lists\n",
    "    card_names = cards_dict[\"data\"].keys()\n",
    "    for cardName in card_names:\n",
    "        # Skip unwanted cards\n",
    "        if isExcluded(cardName): continue\n",
    "\n",
    "        # Get the card text from the card (this will be in a list to account for multi-face cards)\n",
    "        text = getRawText(cardName)\n",
    "\n",
    "        # Clean the text\n",
    "        cleanText = preprocessText(text, cardName) \n",
    "\n",
    "        # Add card names and text to parallel lists\n",
    "        cardNames.append(cardName)\n",
    "        cardTexts.append(cleanText)\n",
    "        \n",
    "    return cardNames, cardTexts\n",
    "\n",
    "# Make the corpus\n",
    "cardNames, cardTexts = constructCorpus()\n",
    "\n",
    "# Debugging method for accessing the processed text of a card\n",
    "def getCleanText(cardName):\n",
    "    return cardTexts[cardNames.index(cardName)]\n",
    "\n",
    "# Example - print some of the corpus\n",
    "for i in range(3):\n",
    "    print(\"CARD: \" + cardNames[i])\n",
    "    print(\"TEXT: \" + cardTexts[i] + \"\\n\")\n",
    "print(\"etc...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TF-IDF Model\n",
    "We can now tokenize our text, stem each token, and then use these tokens to train our TF-IDF model.\n",
    "Try experimenting with the parameters to fine-tune the model (things like min/max doc freq, stop words, etc.).  \n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html  \n",
    "Reference Tutorial: https://www2.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html  \n",
    "*Note: this usually takes a few seconds.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for tfidf - breaks text into list of tokens.\n",
    "def tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "# Helper for tokenize - stemming means removing the suffix from a word to reduce it to its root word.\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "# We can ignore some of the more common words in magic cards that don't add much to the overall meaning of a card. Handmade so this might be missing some.\n",
    "my_stop_words = [\"a\",\"an\",\"and\",\"and/or\",\"are\",\"as\",\"at\",\"be\",\"by\",\"could\",\"dont\",\"for\",\"if\",\"in\",\"is\",\"it\",\"its\",\"may\",\"of\",\"on\",\"or\",\"that\",\"thats\",\"the\",\"their\",\"them\",\"then\",\"they\",\"thi\",\"those\",\"to\",\"wa\",\"where\",\"with\",\"you\",\"your\",\"—\"]\n",
    "\n",
    "# Train the tf-idf model: get vectors representing each card\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words=my_stop_words)\n",
    "tfs = tfidf.fit_transform(cardTexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar Cards\n",
    "Finally, we can search for the most similar cards. Since each card has a TF-IDF vector, we can use cosine similarity to find vectors that are most similar to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  ['Fire // Ice', 'Electrolyze', 'Forked Bolt', \"Chandra's Pyrohelix\", 'Twin Bolt', 'Flames of the Firebrand', 'Arc Lightning', 'Forked Lightning', 'Aerial Volley', 'Fire at Will', 'Deft Dismissal', 'Gang of Devils', 'Arc Mage', 'Ignite Disorder', 'Rolling Thunder', 'Pyrotechnics', 'Boulderfall', 'Hail of Arrows', 'Spreading Flames', 'Inferno Titan'] and so on...\n",
      "\n",
      "CLOSEST 5 CARDS TO Fire // Ice: \n",
      "\n",
      "CARD: Fire // Ice\n",
      "TEXT: Fire deals 2 damage divided as you choose among one or two targets. Tap target permanent.\n",
      "Draw a card.\n",
      "\n",
      "CARD: Electrolyze\n",
      "TEXT: Electrolyze deals 2 damage divided as you choose among one or two targets.\n",
      "Draw a card.\n",
      "\n",
      "CARD: Forked Bolt\n",
      "TEXT: Forked Bolt deals 2 damage divided as you choose among one or two targets.\n",
      "\n",
      "CARD: Chandra's Pyrohelix\n",
      "TEXT: Chandra's Pyrohelix deals 2 damage divided as you choose among one or two targets.\n",
      "\n",
      "CARD: Twin Bolt\n",
      "TEXT: Twin Bolt deals 2 damage divided as you choose among one or two targets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/a/12128777 \n",
    "def getSimilarTexts(cardText, n):\n",
    "    # Calculate all cosine similarities with the inputText\n",
    "    response = tfidf.transform([cardText])\n",
    "    cosine_similarities = cosine_similarity(response, tfs).flatten()\n",
    "\n",
    "    # Sort all the cosine similarities and keep the top n closest\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-n-1:-1]\n",
    "    closest = [cardNames[idx] for idx in related_docs_indices]\n",
    "    return closest #list of card names (strings)\n",
    "\n",
    "def getSimilarCards(cardName, n):\n",
    "    cardText = preprocessText(getRawText(cardName), cardName)\n",
    "    return getSimilarTexts(cardText, n)\n",
    "\n",
    "def printNClosest(cardName, n):\n",
    "    print(\"CLOSEST \" + str(n) + \" CARDS TO \" + cardName + \": \\n\")\n",
    "    for name in getSimilar(cardName, n):\n",
    "        print(\"CARD: \" + name + \"\\nTEXT: \" + getRawText(name) + \"\\n\")\n",
    "\n",
    "# Example:\n",
    "print(\"RESULTS: \", getSimilarCards('Fire // Ice', 20), \"and so on...\\n\")\n",
    "printNClosest('Fire // Ice', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 1: Giant Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOSEST 5 CARDS TO Giant Growth: \n",
      "\n",
      "CARD: Bounty of Might\n",
      "TEXT: Target creature gets +3/+3 until end of turn.\n",
      "Target creature gets +3/+3 until end of turn.\n",
      "Target creature gets +3/+3 until end of turn.\n",
      "\n",
      "CARD: Giant Growth\n",
      "TEXT: Target creature gets +3/+3 until end of turn.\n",
      "\n",
      "CARD: Brute Force\n",
      "TEXT: Target creature gets +3/+3 until end of turn.\n",
      "\n",
      "CARD: Seal of Strength\n",
      "TEXT: Sacrifice Seal of Strength: Target creature gets +3/+3 until end of turn.\n",
      "\n",
      "CARD: Sudden Strength\n",
      "TEXT: Target creature gets +3/+3 until end of turn.\n",
      "Draw a card.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNClosest('Giant Growth', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 2: Young Pyromancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOSEST 5 CARDS TO Young Pyromancer: \n",
      "\n",
      "CARD: Young Pyromancer\n",
      "TEXT: Whenever you cast an instant or sorcery spell, create a 1/1 red Elemental creature token.\n",
      "\n",
      "CARD: Blaze Commando\n",
      "TEXT: Whenever an instant or sorcery spell you control deals damage, create two 1/1 red and white Soldier creature tokens with haste.\n",
      "\n",
      "CARD: Tempt with Vengeance\n",
      "TEXT: Tempting offer — Create X 1/1 red Elemental creature tokens with haste. Each opponent may create X 1/1 red Elemental creature tokens with haste. For each opponent who does, create X 1/1 red Elemental creature tokens with haste.\n",
      "\n",
      "CARD: Scampering Scorcher\n",
      "TEXT: When Scampering Scorcher enters the battlefield, create two 1/1 red Elemental creature tokens. Elementals you control gain haste until end of turn. (They can attack and {T} this turn.)\n",
      "\n",
      "CARD: Seasoned Pyromancer\n",
      "TEXT: When Seasoned Pyromancer enters the battlefield, discard two cards, then draw two cards. For each nonland card discarded this way, create a 1/1 red Elemental creature token.\n",
      "{3}{R}{R}, Exile Seasoned Pyromancer from your graveyard: Create two 1/1 red Elemental creature tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printNClosest(\"Young Pyromancer\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3: A Made-up Card\n",
    "This also works with arbitrary card text - doesn't have to be a real card.  \n",
    "Here I invented a card with the ability: \"Flip a coin; if heads, you win the game immediately. If tails, you lose the game.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOSEST 5 CARDS TO 'MY_MADEUP_CARD': \n",
      "\n",
      "CARD: Platinum Angel\n",
      "TEXT: Flying\n",
      "You can't lose the game and your opponents can't win the game.\n",
      "\n",
      "CARD: Abyssal Persecutor\n",
      "TEXT: Flying, trample\n",
      "You can't win the game and your opponents can't lose the game.\n",
      "\n",
      "CARD: Platinum Angel Avatar\n",
      "TEXT: If you control an artifact, a creature, an enchantment, and a land, you can't lose the game and your opponents can't win the game.\n",
      "\n",
      "CARD: Mana Clash\n",
      "TEXT: You and target opponent each flip a coin. Mana Clash deals 1 damage to each player whose coin comes up tails. Repeat this process until both players' coins come up heads on the same flip.\n",
      "\n",
      "CARD: Amulet of Quoz\n",
      "TEXT: Remove Amulet of Quoz from your deck before playing if you're not playing for ante.\n",
      "{T}, Sacrifice Amulet of Quoz: Target opponent may ante the top card of their library. If they don't, you flip a coin. If you win the flip, that player loses the game. If you lose the flip, you lose the game. Activate this ability only during your upkeep.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "madeupCardText = \"Flip a coin; if heads, you win the game immediately. If tails, you lose the game.\"\n",
    "closest = getSimilarTexts(madeupCardText, 5)\n",
    "\n",
    "print(\"CLOSEST 5 CARDS TO 'MY_MADEUP_CARD': \\n\")\n",
    "for name in closest:\n",
    "    print(\"CARD: \" + name + \"\\nTEXT: \" + getRawText(name) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for checking out my project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
